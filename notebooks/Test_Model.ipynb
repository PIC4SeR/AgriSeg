{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6130acb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806728f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:02.091270Z",
     "start_time": "2023-06-29T08:46:01.900984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup Notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3d98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.090917Z",
     "start_time": "2023-06-29T08:46:02.092475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, gc\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "from utils.train import Trainer\n",
    "from utils.distiller import Distiller\n",
    "from utils.tools import *\n",
    "from utils.preprocess import *\n",
    "from utils.visualize import *\n",
    "from utils.training_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the working GPU\n",
    "id = 4\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[id], 'GPU')\n",
    "devices = []\n",
    "for g in [id]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.108036Z",
     "start_time": "2023-06-29T08:46:03.092015Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = read_yaml('cfg/cfg_2.yaml')\n",
    "cfg['ID'] = 0\n",
    "cfg['SEED'] = 42\n",
    "cfg['METHOD'] = 'None'\n",
    "cfg['UNISTYLE'] = False\n",
    "cfg['WHITEN_LAYERS'] = []\n",
    "cfg['TEST'] = True\n",
    "cfg['WEIGHTS'] = None\n",
    "cfg['IMG_SIZE_TEST'] = [224,224]\n",
    "model_root= Path('bin/Benchmark/Test')\n",
    "label = 'KD'\n",
    "model_path = model_root.joinpath(label)\n",
    "weights = [model_path.joinpath(f) for f in os.listdir(model_path) if f.endswith('.h5')] # new_hilr_chard_KD_1.h5\n",
    "# targets = ['tree_2', 'chard', 'lettuce', 'vineyard'] #, 'pear', 'zucchini', 'vineyard_real', 'misc']\n",
    "targets = ['freiburg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6b4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.124138Z",
     "start_time": "2023-06-29T08:46:03.109181Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Stop execution \n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ddf261d",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d60c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mobilenet_v3 import MobileNetV3Large\n",
    "from utils.models import build_model_binary, build_model_multi\n",
    "from pathlib import Path\n",
    "\n",
    "def get_single_model(self, weights=None, feats=True, whiten=False):\n",
    "    whiten_layers = self.cfg['WHITEN_LAYERS'] if whiten \\\n",
    "                    and self.cfg['UNISTYLE'] \\\n",
    "                    and self.cfg['METHOD'] in ['KD'] else []\n",
    "    \n",
    "    backbone = MobileNetV3Large(input_shape=(self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'], 3),\n",
    "                                alpha=1.0,\n",
    "                                minimalistic=False,\n",
    "                                include_top=False,\n",
    "                                weights='imagenet',\n",
    "                                input_tensor=None,\n",
    "                                classes=self.cfg['N_CLASSES'],\n",
    "                                pooling='avg',\n",
    "                                dropout_rate=False,\n",
    "                                include_preprocessing=self.cfg['NORM']=='tf',\n",
    "                                mode=self.cfg['METHOD'], p=self.cfg['PADAIN']['P'],\n",
    "                                eps=float(self.cfg['PADAIN']['EPS']),\n",
    "                                whiten_layers=whiten_layers,\n",
    "                                wcta=self.cfg['WCTA'] if feats or 'wcta' in self.cfg['TEACHERS'] else False, \n",
    "                                backend=tf.keras.backend, layers=tf.keras.layers, models=tf.keras.models, \n",
    "                                utils=tf.keras.utils\n",
    "                                )\n",
    "\n",
    "    if self.cfg['CITYSCAPES']:\n",
    "        pre_trained_model = build_model_multi(backbone, False, 20)\n",
    "        pre_trained_model.load_weights(self.model_dir.joinpath('lr_aspp_pretrain_cityscapes.h5'))\n",
    "    else:\n",
    "        pre_trained_model = backbone\n",
    "        \n",
    "    if self.cfg['FREEZE_BACKBONE']:\n",
    "        pre_trained_model.trainable = False\n",
    "\n",
    "    # binary segmentation model\n",
    "    model = build_model_binary(pre_trained_model, False, self.cfg['N_CLASSES'], \n",
    "                                sigmoid=self.cfg['LOSS']=='iou', mode=self.cfg['METHOD'],\n",
    "                                p=self.cfg['PADAIN']['P'], eps=float(self.cfg['PADAIN']['EPS']),\n",
    "                                fwcta=self.cfg['FWCTA'] if feats or 'fwcta' in self.cfg['TEACHERS'] else False,\n",
    "                                return_feats=feats)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(self.model_dir.joinpath(weights))\n",
    "    \n",
    "    del pre_trained_model\n",
    "    del backbone\n",
    "    gc.collect()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_teacher(self):\n",
    "    domains = [w for w in self.cfg['SOURCE'] if w != self.cfg['TARGET']]\n",
    "    if self.cfg['ERM_TEACHERS']:\n",
    "        weights = [f'teachers/erm/teacher_{self.cfg[\"TARGET\"]}.h5']\n",
    "    else:\n",
    "        weights = [f'teachers/{self.cfg[\"TEACHERS\"]}/teacher_{w}.h5' for w in domains]\n",
    "    print(f'Loaded Teachers: {domains}')\n",
    "    \n",
    "    models = [self.get_single_model(w, feats=False) for w in weights]\n",
    "    \n",
    "    model_input = tf.keras.Input(shape=(self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'], 3))\n",
    "    model_outputs = [model(model_input) for model in models]\n",
    "    self.teacher = tf.keras.Model(inputs=model_input, outputs=model_outputs)\n",
    "    \n",
    "    del models\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573a242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:11.471560Z",
     "start_time": "2023-06-29T08:49:11.455723Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test_fn(cfg,\n",
    "            model_path,\n",
    "            targets,\n",
    "            strategy=None, \n",
    "            ensemble=False):\n",
    "    \n",
    "    res = []\n",
    "    for model_name in model_path:\n",
    "        print(str(model_name))\n",
    "        for t in targets:\n",
    "            # if t not in str(model_name):\n",
    "            #     continue\n",
    "            tf.keras.backend.clear_session()\n",
    "            cfg['TARGET'] = t\n",
    "            \n",
    "            if cfg['METHOD'] != 'KD':\n",
    "                trainer = Trainer(cfg, logger=None, strategy=strategy, test=True)\n",
    "            else:\n",
    "                trainer = Distiller(cfg, logger=None, strategy=strategy, test=True)\n",
    "\n",
    "            # trainer.model.summary()\n",
    "            if ensemble:\n",
    "                trainer.model = get_teacher(cfg)\n",
    "            else:\n",
    "                trainer.model.load_weights(str(model_name))\n",
    "            \n",
    "            loss, metric = trainer.evaluate(trainer.ds_test, 'test')\n",
    "            print(metric.numpy())\n",
    "            print('')\n",
    "            res.append(metric.numpy())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8dece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:14.131661Z",
     "start_time": "2023-06-29T08:49:12.823328Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(f'{target}\\n')\n",
    "    res = test_fn(cfg,\n",
    "                  weights,\n",
    "                  [target],\n",
    "                  strategy=None,\n",
    "                  ensemble=False)\n",
    "    print(f'{target}: {np.mean(res)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573da53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.071768Z",
     "start_time": "2023-06-29T08:46:05.071762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stop execution\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(map(weights.__getitem__, [1, 4, 7, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a46cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:11.967578Z",
     "start_time": "2023-06-29T08:49:11.940859Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize function\n",
    "def visualize_fn(cfg,\n",
    "                 model_path,\n",
    "                 targets,\n",
    "                 strategy=None,\n",
    "                 n=1,\n",
    "                 conf=0.0,\n",
    "                 soft=False,\n",
    "                 save=False):\n",
    "    ts = {}\n",
    "    plt.rcParams['figure.figsize'] = [4, 4]\n",
    "    \n",
    "    for model_name in model_path:\n",
    "        print(str(model_name))\n",
    "        cfg['TARGET'] = None\n",
    "        for t in targets:\n",
    "            # if t in str(model_name):\n",
    "            cfg['TARGET'] = t\n",
    "            if cfg['TARGET'] is None:\n",
    "                cfg['TARGET'] = targets\n",
    "            tf.keras.backend.clear_session()\n",
    "            trainer = Trainer(cfg, logger=None, strategy=strategy)\n",
    "            trainer.model.load_weights(str(model_name))\n",
    "            c = n\n",
    "            for image, y in trainer.ds_test:\n",
    "                i = tf.cast((image[0] + 0) * 1.0, tf.uint8)\n",
    "                plt.imshow(i, alpha=1.0) \n",
    "                plt.axis('off')\n",
    "                if save:\n",
    "                    plt.savefig(f'./demo/Input_{cfg[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)  \n",
    "                plt.show()\n",
    "                plt.imshow(y[0], alpha=1.0) \n",
    "                plt.axis('off')\n",
    "                if save:\n",
    "                    plt.savefig(f'./demo/GT_{cfg[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)   \n",
    "                plt.show()   \n",
    "                out = trainer.model.predict(image[:1], verbose=0)[0][0]\n",
    "                out = tf.math.sigmoid(out)\n",
    "\n",
    "                if conf:\n",
    "                    if soft:\n",
    "                        plt.imshow(out*tf.cast(out>conf, tf.float32), alpha=1)\n",
    "                    else:\n",
    "                        plt.imshow(out>conf, alpha=1)\n",
    "                else:\n",
    "                    plt.imshow(out, alpha=1.)\n",
    "                plt.axis('off')\n",
    "\n",
    "                if save:\n",
    "                    plt.savefig(f'./demo/{label}_{cfg[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)\n",
    "                \n",
    "                plt.show()\n",
    "\n",
    "                c -= 1\n",
    "                if c < 0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1be96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:12.292336Z",
     "start_time": "2023-06-29T08:49:12.278667Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "ls = visualize_fn(\n",
    "    cfg,\n",
    "    weights,\n",
    "    targets,\n",
    "    strategy=None,\n",
    "    conf=0.,\n",
    "    soft=False,\n",
    "    save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5a7adda",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabdb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.072476Z",
     "start_time": "2023-06-29T08:46:05.072470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cfg = read_yaml('utils/cfg.yaml')\n",
    "cfg['SEED'] = 0\n",
    "cfg['NAME'] = 'test'\n",
    "cfg['ID'] = 0\n",
    "cfg['BATCH_SIZE'] = 1\n",
    "\n",
    "cfg['TARGET'] = 'misc'\n",
    "cfg['METHOD'] = 'XDED'\n",
    "cfg['WHITEN_LAYERS'] = []\n",
    "cfg['ERM_TEACHERS'] = False\n",
    "\n",
    "\n",
    "model_name = 'bin/Benchmark/XDED_01_new/XDED_01_new_vineyard_real_new_XDED_5.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a94a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.072877Z",
     "start_time": "2023-06-29T08:46:05.072872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_some_samples(trainer, n=1, conf=0.0, save=False, mode=None):\n",
    "    for image, _ in trainer.ds_test:\n",
    "        if mode == 'KD':\n",
    "            out = trainer.teacher.predict(image[:1], verbose=0)[0]\n",
    "        else:\n",
    "            out = trainer.model.predict(image[:1], verbose=0)[0][0]\n",
    "        out = tf.math.sigmoid(out)#/trainer.cfg['KD']['T']) # \n",
    "        \n",
    "        i = tf.cast((image[0] + 1) * 127.5, tf.uint8)\n",
    "        plt.imshow(i, alpha=1.) \n",
    "        plt.axis('off')\n",
    "        if save:\n",
    "            plt.savefig(f'./demo/in_{trainer.cfg[\"TARGET\"]}_{n-1}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        if conf:\n",
    "            plt.imshow(out>conf, alpha=1)\n",
    "        else:\n",
    "            plt.imshow(out, alpha=1)\n",
    "        plt.axis('off')\n",
    "        if save:\n",
    "            plt.savefig(f'./demo/out_{trainer.cfg[\"TARGET\"]}_{trainer.cfg[\"METHOD\"]}_{n-1}.png', bbox_inches='tight')\n",
    "    \n",
    "        n -= 1\n",
    "        if n <= 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d3306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.073398Z",
     "start_time": "2023-06-29T08:46:05.073393Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cfg['TARGET'] in ['lettuce']:\n",
    "    if cfg['METHOD'] != 'KD':\n",
    "        trainer = Trainer(cfg, logger=None, strategy=None, test=True)\n",
    "    else:\n",
    "        trainer = Distiller(cfg, logger=None, strategy=None, test=False)  \n",
    "    trainer.model.load_weights(model_name)\n",
    "    predict_some_samples(trainer, n=9, conf=0., save=True, mode=None)\n",
    "    #trainer.evaluate(trainer.ds_test, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f10f207",
   "metadata": {},
   "source": [
    "# TFLIite Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c35aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.073781Z",
     "start_time": "2023-06-29T08:46:05.073776Z"
    }
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc12b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.074237Z",
     "start_time": "2023-06-29T08:46:05.074232Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(trainer.model)\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "name_model_tflite = 'lavanda.tflite'\n",
    "tflite_model_file = Path(cfg['MODEL_PATH']).joinpath(name_model_tflite)                          \n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb45330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.074635Z",
     "start_time": "2023-06-29T08:46:05.074630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"bin/lavanda.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db90c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075003Z",
     "start_time": "2023-06-29T08:46:05.074998Z"
    }
   },
   "outputs": [],
   "source": [
    "output_details[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b0717c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# XDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108df2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075422Z",
     "start_time": "2023-06-29T08:46:05.075418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927af9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075845Z",
     "start_time": "2023-06-29T08:46:05.075840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pixelwise_XDEDLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temp_factor=2.0):\n",
    "        super(pixelwise_XDEDLoss, self).__init__()\n",
    "        self.temp_factor = temp_factor\n",
    "        self.kl_div = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.SUM)\n",
    "        self.CLASS_NUM = 1\n",
    "\n",
    "    def xded_loss(self, input, target):\n",
    "        \n",
    "        loss = self.kl_div(tf.nn.softmax(input/self.temp_factor, axis=-1),\n",
    "                           tf.nn.softmax(target/self.temp_factor, axis=-1)) * (self.temp_factor**2)/input.shape[0]\n",
    "        return loss\n",
    "\n",
    "    def call(self, main_out, gts):\n",
    "        # main_out.shape : [batch, 1, 768, 768]\n",
    "        # gts.shape : [batch, 768, 768]\n",
    "\n",
    "        batch_size = main_out.shape[0]\n",
    "        print(batch_size)\n",
    "        flat_gts = tf.reshape(gts,[-1,1]) # [batch*768*768]\n",
    "        flat_out = tf.reshape(main_out,(-1, self.CLASS_NUM))\n",
    "        not_flat_out = not flat_out\n",
    "\n",
    "        flat_targets = tf.reshape(main_out,(-1, self.CLASS_NUM))\n",
    "        # [batch*768*768, 1]\n",
    "\n",
    "        cur_gt_idx = flat_gts == 1 # [False, True, ...]\n",
    "        not_cur_gt_idx = flat_gts == 0 # [True, False, ...]\n",
    "        print(cur_gt_idx.shape)\n",
    "        \n",
    "        x = tf.boolean_mask(flat_out,cur_gt_idx)\n",
    "        not_x = tf.boolean_mask(flat_out,not_cur_gt_idx)\n",
    "        \n",
    "        flat_targets = tf.reduce_mean(x) * tf.cast(cur_gt_idx,tf.float32)\n",
    "        not_flat_targets = tf.reduce_mean(not_x) * tf.cast(not_cur_gt_idx,tf.float32)\n",
    "        print(flat_out.shape, not_flat_out.shape)\n",
    "        print(flat_targets.shape, not_flat_targets.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.xded_loss(flat_out, flat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.076211Z",
     "start_time": "2023-06-29T08:46:05.076206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ys = tf.random.uniform((64,224,224,1))*10\n",
    "y  = tf.cast(tf.random.uniform((64,224,224,1),maxval=2,dtype=tf.int32), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb37f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.076634Z",
     "start_time": "2023-06-29T08:46:05.076630Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(np.min(ys), np.max(ys))\n",
    "print(np.min(y), np.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df79fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.077082Z",
     "start_time": "2023-06-29T08:46:05.077077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(y_pred,y):\n",
    "    l = pixelwise_XDEDLoss()\n",
    "    return l(y_pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fc499",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ec38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.8/extras/CUPTI/lib64:$LD_LIBRARY_PATH'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sysconfig.get_build_info() \n",
    "\n",
    "# GPU setup\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", physical_devices)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "devices = []\n",
    "for g in [0]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b262a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.0/extras/CUPTI/lib64:$LD_LIBRARY_PATH'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH'\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from utils.tools import read_yaml\n",
    "from utils.data import load_multi_dataset, split_data, random_flip, random_resize_crop, random_jitter, random_grayscale\n",
    "\n",
    "# GPU setup\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", physical_devices)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "devices = []\n",
    "for g in [0]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')\n",
    "    \n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "cfg = read_yaml('utils/cfg.yaml')\n",
    "cfg['TARGET'] = 'lettuce'\n",
    "cfg['NAME'] = 'test'\n",
    "cfg['ID'] = 0\n",
    "cfg['STYLE_AUG'] = False\n",
    "cfg['RND_FLIP'] = 0.0\n",
    "cfg['RND_CROP'] = 1.0\n",
    "cfg['RND_GREY'] = 0.0\n",
    "cfg['RND_JITTER'] = 0.0\n",
    "cfg['RND_JITTER_RNG'] = 0.0\n",
    "data_dir = Path(cfg['DATA_PATH'])\n",
    "\n",
    "def get_data(cfg, data_dir):\n",
    "\n",
    "    target_dataset = data_dir.joinpath(cfg['TARGET'])\n",
    "    source_dataset = sorted([data_dir.joinpath(d) for d in cfg['SOURCE'] if d != cfg['TARGET']])\n",
    "    \n",
    "    ds_source, ds_target = load_multi_dataset(source_dataset, target_dataset, cfg)\n",
    "    ds_train, ds_val, ds_test = split_data(ds_source, ds_target, cfg)\n",
    "    \n",
    "    train_len = len(ds_train)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(train_len)\n",
    "    ds_train = ds_train.map(lambda x, y: random_flip(x, y, p=cfg['RND_FLIP']), tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.map(lambda x, y: random_resize_crop(x, y, min_p=cfg['RND_CROP']), tf.data.experimental.AUTOTUNE)\n",
    "    if cfg['STYLE_AUG']:\n",
    "        ds_train = ds_train.map(lambda x, y: random_jitter(x, y, p=cfg['RND_JITTER'], r=cfg['RND_JITTER_RNG']), tf.data.experimental.AUTOTUNE)\n",
    "        ds_train = ds_train.map(lambda x, y: random_grayscale(x, y, p=cfg['RND_GREY']), tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.batch(8, drop_remainder=True)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_len = 0\n",
    "\n",
    "    if ds_test is not None:\n",
    "        test_len = len(ds_test)\n",
    "        # ds_test = ds_test.cache()\n",
    "        ds_train = ds_train.shuffle(test_len)\n",
    "        ds_test = ds_test.batch(8, drop_remainder=False)\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    else: \n",
    "        test_len = 0\n",
    "        \n",
    "    print(f'Loaded data: Train {train_len}, Val {val_len}, Test {test_len}')\n",
    "    return ds_train, ds_val, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643211c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = get_data(cfg, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e962792",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(ds_test, 1):\n",
    "    # aug_x = _instance_norm_block(x, mode='KD_WCTA', training=True)\n",
    "    for i in range(x.shape[0]):\n",
    "        print(tf.reduce_min(x[i]), tf.reduce_max(x[i]), tf.reduce_mean(x[i]))\n",
    "        plt.imshow(x[i]*std+mean)\n",
    "        print(tf.reduce_min(x[i]*std+mean), tf.reduce_max(x[i]*std+mean), tf.reduce_mean(x[i]*std+mean))\n",
    "        plt.show()\n",
    "        # plt.imshow(aug_x[i]*std+mean)\n",
    "        # plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open('../AgriSeg_Dataset/lettuce/lettuce_1/images/Image10/Image0001.png'))[:,:,:3]\n",
    "img = img/255.0\n",
    "img -= [0.485, 0.456, 0.406]\n",
    "img /= [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min(), img.max(), img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from utils.mobilenet_v3 import MobileNetV3Large\n",
    "from utils.models import build_model_binary\n",
    "\n",
    "#select the working GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[7], 'GPU')\n",
    "devices = []\n",
    "for g in [7]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')\n",
    "\n",
    "pre_trained_model = MobileNetV3Large(\n",
    "    input_shape=(224,224,3),\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    classes=1,\n",
    "    pooling='avg',\n",
    "    dropout_rate=False,\n",
    "    include_preprocessing=True,\n",
    "    mode=\"KD\", p=0, eps=1e-5, whiten_layers=[], wcta=True, fwcta=True, \n",
    "    backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils\n",
    "    )\n",
    "\n",
    "pre_trained_model.trainable = False\n",
    "\n",
    "model = build_model_binary(pre_trained_model, False, 1, \n",
    "    sigmoid=False, mode=\"KD\",\n",
    "    p=0, eps=1e-5, return_feats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d02216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tf.random.normal((1,224,224,3)), training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4de925",
   "metadata": {},
   "source": [
    "# Gradient Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#select the working GPU\n",
    "id = 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[id], 'GPU')\n",
    "devices = []\n",
    "for g in [id]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.constant([[[[1, 0, 0], [0, 1, 1], [0, 0, 1]]], \n",
    "                 [[[1, 0, 0], [0, 1, 1], [0, 0, 1]]]])\n",
    "print(y)\n",
    "pred_t = tf.constant([[[[0.6, 0.8, 0.2], [0.3, 0.1, 0.9991], [0.7, 0.0, 0.8]]], \n",
    "                      [[[0.6, 0.8, 0.2], [0.3, 0.1, 0.9999], [0.7, 0.0, 0.8]]]])\n",
    "print(pred_t)\n",
    "aux_loss = tf.constant([[[[0.4, 0.8, 0.2], [0.3, 0.9, 0.1], [0.7, 0.0, 0.2]]], \n",
    "                        [[[0.4, 0.8, 0.2], [0.3, 0.9, 0.1], [0.7, 0.0, 0.2]]]])\n",
    "print(aux_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d941e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_filter(p, n=0.999):\n",
    "    a = tf.cast(tf.where(p <= n, 1, 0), bool)\n",
    "    b = tf.cast(tf.where(p > (1+n)/2, 1, 0), bool)\n",
    "    c = tf.logical_not(tf.logical_or(a, b))\n",
    "    # print(a, b, c)\n",
    "    o = tf.cast(tf.where(a, 1, 0), tf.float32) + tf.cast(tf.where(c, ((n+1-2*p) / (1-n)) ** 2, 0), tf.float32)\n",
    "    # print(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf27027",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_filter(pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence\n",
    "\n",
    "def loss_filter(p, n=0.999):\n",
    "    if p <= n:\n",
    "        return 1\n",
    "    elif p > (1+n)/2:\n",
    "        return 0\n",
    "    else:\n",
    "        return ((n+1-2*p) / (1-n)) ** 2\n",
    "\n",
    "old_loss = tf.reduce_mean(aux_loss)\n",
    "print(old_loss)\n",
    "shape = tf.shape(pred_t)\n",
    "w = tf.map_fn(loss_filter, tf.reshape(pred_t, [-1]), dtype=tf.float32)\n",
    "w = tf.reshape(w, shape)\n",
    "print(w)\n",
    "aux_loss = aux_loss * w\n",
    "print(aux_loss)\n",
    "aux_loss = tf.reduce_mean(aux_loss)\n",
    "print(aux_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "\n",
    "pred_t_bin = tf.math.greater(pred_t, tf.constant([0.5]))\n",
    "print(pred_t_bin)\n",
    "old_loss = tf.reduce_mean(aux_loss)\n",
    "print(old_loss)\n",
    "mask = tf.equal(pred_t_bin, tf.cast(y, tf.bool))\n",
    "print(mask)\n",
    "aux_loss = aux_loss * tf.cast(mask, tf.float32)\n",
    "print(aux_loss)\n",
    "n = tf.math.count_nonzero(aux_loss)\n",
    "print(n)\n",
    "aux_loss = tf.reduce_sum(aux_loss) / tf.cast(n, tf.float32) if n > 0 else 0.0\n",
    "print(aux_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7806ff9",
   "metadata": {},
   "source": [
    "# Teacher Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cfg Completer.use_jedi = False\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd804c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from utils.tools import read_yaml\n",
    "from utils.mobilenet_v3 import MobileNetV3Large\n",
    "from utils.models import build_model_binary\n",
    "from utils.training_tools import uniform_soup\n",
    "\n",
    "#select the working GPU\n",
    "id = 0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[id], 'GPU')\n",
    "devices = []\n",
    "for g in [id]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester():\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.model_dir = Path(cfg['MODEL_PATH'])\n",
    "        self.model = None\n",
    "        self.teacher = None\n",
    "\n",
    "    def get_student(self):\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        self.model = self.get_single_model(whiten=True)\n",
    "        \n",
    "        \n",
    "    def get_single_model(self, weights=None, feats=True, whiten=False):\n",
    "        whiten_layers = self.cfg['WHITEN_LAYERS'] if whiten \\\n",
    "                        and self.cfg['UNISTYLE'] \\\n",
    "                        and self.cfg['METHOD'] in ['KD'] else []\n",
    "            \n",
    "        backbone = MobileNetV3Large(input_shape=(self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'], 3),\n",
    "                                    alpha=1.0,\n",
    "                                    minimalistic=False,\n",
    "                                    include_top=False,\n",
    "                                    weights='imagenet',\n",
    "                                    input_tensor=None,\n",
    "                                    classes=self.cfg['N_CLASSES'],\n",
    "                                    pooling='avg',\n",
    "                                    dropout_rate=False,\n",
    "                                    include_preprocessing=self.cfg['NORM']=='tf',\n",
    "                                    mode=self.cfg['METHOD'], p=self.cfg['PADAIN']['P'],\n",
    "                                    eps=float(self.cfg['PADAIN']['EPS']),\n",
    "                                    whiten_layers=whiten_layers,\n",
    "                                    wcta=self.cfg['WCTA'] if feats or 'wcta' in self.cfg['TEACHERS'] else False, \n",
    "                                    backend=tf.keras.backend, layers=tf.keras.layers, models=tf.keras.models, \n",
    "                                    utils=tf.keras.utils\n",
    "                                    )\n",
    "\n",
    "        if self.cfg['CITYSCAPES']:\n",
    "            pre_trained_model = build_model_multi(backbone, False, 20)\n",
    "            pre_trained_model.load_weights(self.model_dir.joinpath('lr_aspp_pretrain_cityscapes.h5'))\n",
    "        else:\n",
    "            pre_trained_model = backbone\n",
    "            \n",
    "        if self.cfg['FREEZE_BACKBONE']:\n",
    "            pre_trained_model.trainable = False\n",
    "\n",
    "        # binary segmentation model\n",
    "        model = build_model_binary(pre_trained_model, False, self.cfg['N_CLASSES'], \n",
    "                                    sigmoid=self.cfg['LOSS']=='iou', mode=self.cfg['METHOD'],\n",
    "                                    p=self.cfg['PADAIN']['P'], eps=float(self.cfg['PADAIN']['EPS']),\n",
    "                                    fwcta=self.cfg['FWCTA'] if feats or 'fwcta' in self.cfg['TEACHERS'] else False,\n",
    "                                    return_feats=feats)\n",
    "        \n",
    "        if weights:\n",
    "            model.load_weights(self.model_dir.joinpath(weights))\n",
    "        \n",
    "        del pre_trained_model\n",
    "        del backbone\n",
    "        gc.collect()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def get_teacher(self):\n",
    "        domains = [w for w in self.cfg['SOURCE'] if w != self.cfg['TARGET']]\n",
    "        if self.cfg['ERM_TEACHERS']:\n",
    "            weights = [f'teachers/erm/teacher_{self.cfg[\"TARGET\"]}.h5']\n",
    "        else:\n",
    "            weights = [f'teachers/{self.cfg[\"TEACHERS\"]}/teacher_{w}.h5' for w in domains]\n",
    "        print(f'Loaded Teachers: {domains}')\n",
    "        \n",
    "        models = [self.get_single_model(w, feats=False) for w in weights]\n",
    "        \n",
    "        if self.cfg['SOUP']:\n",
    "            # average teacher weights\n",
    "            self.model = uniform_soup(self.get_single_model(feats=True), [self.model_dir.joinpath(w) for w in weights])\n",
    "\n",
    "        model_input = tf.keras.Input(shape=(self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'], 3))\n",
    "        model_outputs = [model(model_input) for model in models]\n",
    "        # ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "        # self.teacher = tf.keras.Model(inputs=model_input, outputs=ensemble_output)\n",
    "        self.teacher = tf.keras.Model(inputs=model_input, outputs=model_outputs)\n",
    "        \n",
    "        del models\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_yaml('cfg/cfg_3.yaml')\n",
    "cfg['TARGET'] = 'tree_2'\n",
    "cfg['NAME'] = 'test'\n",
    "cfg['METHOD'] = 'KD'\n",
    "cfg['ID'] = 0\n",
    "cfg['ERM_TEACHERS'] = False\n",
    "cfg['TEST'] = False\n",
    "cfg['TEACHERS'] = f\"{cfg['NORM']}_{'style' if cfg['STYLE_AUG'] else 'geom'}\" + \\\n",
    "                     f\"{'_wcta' if cfg['WCTA'] else ''}\" if cfg['TEACHERS'] is None else cfg['TEACHERS']\n",
    "\n",
    "trainer = Tester(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9332a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_teacher()\n",
    "trainer.get_student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "list_1 = glob.glob(r\"/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/*.jpg\")\n",
    "list_2 = glob.glob(r\"/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/*.png\")\n",
    "list_3 = glob.glob(r\"/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/*\")\n",
    "len(list_1), len(list_2), len(list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ced73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "i = Image.open('/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/image_5.jpg')\n",
    "i.save('/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/image_5.jpg', \"jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82473bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for f in list_1:\n",
    "    os.rename(f, f.replace('.jpeg', '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "\n",
    "data_dir = \"/ssd1/sa58728/AgriSeg_Dataset/misc/misc_1/images/\"\n",
    "image_extensions = [\".png\", \".jpg\", \".jpeg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\", \"jpg\"]\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        img_type = imghdr.what(filepath)\n",
    "        if img_type is None:\n",
    "            print(f\"{filepath} is not an image\")\n",
    "        elif img_type not in img_type_accepted_by_tf:\n",
    "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "        # else:\n",
    "        #     print(f\"{filepath} is a {img_type}, accepted by TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea99028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
