{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6130acb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3d98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.090917Z",
     "start_time": "2023-06-29T08:46:02.092475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from utils.train import Trainer\n",
    "from utils.distiller import Distiller\n",
    "from utils.tools import *\n",
    "from utils.preprocess import *\n",
    "from utils.visualize import *\n",
    "from utils.training_tools import *\n",
    "\n",
    "IMN_STD = [0.229, 0.224, 0.225]\n",
    "IMN_MEAN = [0.485, 0.456, 0.406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f8b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.108036Z",
     "start_time": "2023-06-29T08:46:03.092015Z"
    }
   },
   "outputs": [],
   "source": [
    "config = read_yaml('utils/config.yaml')\n",
    "\n",
    "config['ID'] = 0\n",
    "config['SEED'] = 42\n",
    "config['METHOD'] = 'KD'\n",
    "config['UNISTYLE'] = True\n",
    "config['WHITEN_LAYERS'] = []\n",
    "config['DATA_PATH'] = '../AgriSeg_Dataset/'\n",
    "model_root= Path('bin/Benchmark/')\n",
    "label = 'KD_001'\n",
    "model_path = model_root.joinpath(label)\n",
    "weights = [model_path.joinpath(f) for f in os.listdir(model_path) if f.endswith('.h5')]\n",
    "targets = ['pear', 'zucchini', 'vineyard_real', 'misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6b4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.124138Z",
     "start_time": "2023-06-29T08:46:03.109181Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Stop execution \n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea24b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:03.162726Z",
     "start_time": "2023-06-29T08:46:03.124896Z"
    },
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", physical_devices)\n",
    "\n",
    "#select the working GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "devices = []\n",
    "for g in [0]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=devices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ddf261d",
   "metadata": {},
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d60c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "from utils.mobilenet_v3 import MobileNetV3Large\n",
    "from utils.models import build_model_multi, build_model_binary\n",
    "from pathlib import Path\n",
    "\n",
    "def get_single_model(config, weights=None, feats=True, whiten=False, model_dir=None):\n",
    "        \n",
    "        whiten_layers = config['WHITEN_LAYERS'] if whiten \\\n",
    "                        and config['UNISTYLE'] \\\n",
    "                        and config['METHOD'] in ['KD'] else []\n",
    "            \n",
    "        backbone = MobileNetV3Large(\n",
    "            input_shape=(config['IMG_SIZE'], config['IMG_SIZE'], 3),\n",
    "            alpha=1.0,\n",
    "            minimalistic=False,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_tensor=None,\n",
    "            classes=config['N_CLASSES'],\n",
    "            pooling='avg',\n",
    "            dropout_rate=False,\n",
    "            mode=config['METHOD'], p=config['PADAIN']['P'],\n",
    "            eps=float(config['PADAIN']['EPS']),\n",
    "            whiten_layers=whiten_layers,\n",
    "            backend=tf.keras.backend, layers=tf.keras.layers, models=tf.keras.models, \n",
    "            utils=tf.keras.utils)\n",
    "        \n",
    "        pre_trained_model = backbone\n",
    "\n",
    "        # binary segmentation model\n",
    "        model = build_model_binary(pre_trained_model, False, config['N_CLASSES'], \n",
    "                                    sigmoid=config['LOSS']=='iou', mode=config['METHOD'],\n",
    "                                    p=config['PADAIN']['P'], eps=float(config['PADAIN']['EPS']),\n",
    "                                    return_feats=feats)\n",
    "        \n",
    "        if weights:\n",
    "            model.load_weights(model_dir.joinpath(weights))\n",
    "        model.trainable = True\n",
    "        \n",
    "        return model\n",
    " \n",
    "\n",
    "def get_teacher(config):\n",
    "    domains = [w for w in config['SOURCE'] if w != config['TARGET']]\n",
    "    weights = [f'teachers/teacher_aug_{w}.h5' for w in domains]\n",
    "    print(f'Loaded Teachers: {domains}')\n",
    "    \n",
    "    models = [get_single_model(config, w, feats=False, model_dir=Path('bin/')) for w in weights]\n",
    "    \n",
    "    model_input = tf.keras.Input(shape=(config['IMG_SIZE'], config['IMG_SIZE'], 3))\n",
    "    model_outputs = [model(model_input) for model in models]\n",
    "    ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "    teacher = tf.keras.Model(inputs=model_input, outputs=ensemble_output)\n",
    "    return teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573a242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:11.471560Z",
     "start_time": "2023-06-29T08:49:11.455723Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test_fn(config,\n",
    "            model_path,\n",
    "            targets,\n",
    "            strategy=None, \n",
    "            ensemble=False):\n",
    "    \n",
    "    res = []\n",
    "    for model_name in model_path:\n",
    "        print(str(model_name))\n",
    "        for t in targets:\n",
    "            tf.keras.backend.clear_session()\n",
    "            config['TARGET'] = t\n",
    "            \n",
    "            if config['METHOD'] != 'KD':\n",
    "                trainer = Trainer(config, logger=None, strategy=strategy, test=True)\n",
    "            else:\n",
    "                trainer = Distiller(config, logger=None, strategy=strategy, test=True)\n",
    "\n",
    "            # trainer.model.summary()\n",
    "            if ensemble:\n",
    "                trainer.moddel = get_teacher(config)\n",
    "            else:\n",
    "                trainer.model.load_weights(str(model_name))\n",
    "            \n",
    "            loss, metric = trainer.evaluate(trainer.ds_test, 'test')\n",
    "            print(metric.numpy())\n",
    "            print('')\n",
    "            res.append(metric.numpy())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a46cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:11.967578Z",
     "start_time": "2023-06-29T08:49:11.940859Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize function\n",
    "def visualize_fn(config,\n",
    "                 model_path,\n",
    "                 targets,\n",
    "                 strategy=None,\n",
    "                 n=1,\n",
    "                 conf=0.0,\n",
    "                 soft=False,\n",
    "                 save=False):\n",
    "    ts = {}\n",
    "    plt.rcParams['figure.figsize'] = [4, 4]\n",
    "    \n",
    "    for model_name in model_path:\n",
    "        print(str(model_name))\n",
    "#         for t in targets:\n",
    "#             if t in str(model_name):\n",
    "#                 config['TARGET'] = t\n",
    "        config['TARGET'] = targets[0]\n",
    "        tf.keras.backend.clear_session()\n",
    "        trainer = Trainer(config, logger=None, strategy=strategy, test=True)\n",
    "        trainer.model.load_weights(str(model_name))\n",
    "        c = n\n",
    "        for image, y in trainer.ds_test:\n",
    "            i = tf.cast((image[0] * IMN_STD + IMN_MEAN) * 255.0, tf.uint8)\n",
    "            plt.imshow(i, alpha=1.0) \n",
    "            plt.axis('off')\n",
    "            if save:\n",
    "                plt.savefig(f'./demo/Input_{config[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)  \n",
    "            plt.show()\n",
    "            plt.imshow(y[0], alpha=1.0) \n",
    "            plt.axis('off')\n",
    "            if save:\n",
    "                plt.savefig(f'./demo/GT_{config[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)   \n",
    "            plt.show()   \n",
    "            out = trainer.model.predict(image[:1], verbose=0)[0][0]\n",
    "            out = tf.math.sigmoid(out)\n",
    "\n",
    "            if conf:\n",
    "                if soft:\n",
    "                    plt.imshow(out*tf.cast(out>conf, tf.float32), alpha=1)\n",
    "                else:\n",
    "                    plt.imshow(out>conf, alpha=1)\n",
    "            else:\n",
    "                plt.imshow(out, alpha=1.)\n",
    "            plt.axis('off')\n",
    "\n",
    "            if save:\n",
    "                plt.savefig(f'./demo/{label}_{config[\"TARGET\"]}_{c}.pdf',bbox_inches='tight', pad_inches=0)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "            c -= 1\n",
    "            if c < 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8dece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:14.131661Z",
     "start_time": "2023-06-29T08:49:12.823328Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(f'{target}\\n')\n",
    "    res = test_fn(config,\n",
    "                  weights,\n",
    "                  [target],\n",
    "                  strategy=None,\n",
    "                  ensemble=False)\n",
    "    print(f'{target}: {np.mean(res)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573da53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.071768Z",
     "start_time": "2023-06-29T08:46:05.071762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stop execution\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1be96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:49:12.292336Z",
     "start_time": "2023-06-29T08:49:12.278667Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "ls = visualize_fn(config,\n",
    "             weights,\n",
    "             targets,\n",
    "             strategy=None,\n",
    "             conf=0.0,\n",
    "             soft=False,\n",
    "             save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5a7adda",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabdb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.072476Z",
     "start_time": "2023-06-29T08:46:05.072470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "config = read_yaml('utils/config.yaml')\n",
    "config['SEED'] = 0\n",
    "config['NAME'] = 'test'\n",
    "config['ID'] = 0\n",
    "config['BATCH_SIZE'] = 1\n",
    "\n",
    "config['TARGET'] = 'misc'\n",
    "config['METHOD'] = 'XDED'\n",
    "config['WHITEN_LAYERS'] = []\n",
    "config['ERM_TEACHERS'] = False\n",
    "\n",
    "\n",
    "model_name = 'bin/Benchmark/XDED_01_new/XDED_01_new_vineyard_real_new_XDED_5.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a94a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.072877Z",
     "start_time": "2023-06-29T08:46:05.072872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "IMN_STD = [0.229, 0.224, 0.225]\n",
    "IMN_MEAN = [0.485, 0.456, 0.406]\n",
    "\n",
    "def predict_some_samples(trainer, n=1, conf=0.0, save=False, mode=None):\n",
    "    for image, _ in trainer.ds_test:\n",
    "        if mode == 'KD':\n",
    "            out = trainer.teacher.predict(image[:1], verbose=0)[0]\n",
    "        else:\n",
    "            out = trainer.model.predict(image[:1], verbose=0)[0][0]\n",
    "        out = tf.math.sigmoid(out)#/trainer.config['KD']['T']) # \n",
    "        \n",
    "        i = tf.cast((image[0] * IMN_STD + IMN_MEAN) * 255.0, tf.uint8)\n",
    "        plt.imshow(i, alpha=1.) \n",
    "        plt.axis('off')\n",
    "        if save:\n",
    "            plt.savefig(f'./demo/in_{trainer.config[\"TARGET\"]}_{n-1}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        if conf:\n",
    "            plt.imshow(out>conf, alpha=1)\n",
    "        else:\n",
    "            plt.imshow(out, alpha=1)\n",
    "        plt.axis('off')\n",
    "        if save:\n",
    "            plt.savefig(f'./demo/out_{trainer.config[\"TARGET\"]}_{trainer.config[\"METHOD\"]}_{n-1}.png', bbox_inches='tight')\n",
    "    \n",
    "        n -= 1\n",
    "        if n <= 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d3306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.073398Z",
     "start_time": "2023-06-29T08:46:05.073393Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for config['TARGET'] in ['lettuce']:\n",
    "    if config['METHOD'] != 'KD':\n",
    "        trainer = Trainer(config, logger=None, strategy=None, test=True)\n",
    "    else:\n",
    "        trainer = Distiller(config, logger=None, strategy=None, test=False)  \n",
    "    trainer.model.load_weights(model_name)\n",
    "    predict_some_samples(trainer, n=9, conf=0., save=True, mode=None)\n",
    "    #trainer.evaluate(trainer.ds_test, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f10f207",
   "metadata": {},
   "source": [
    "# TFLIite Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c35aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.073781Z",
     "start_time": "2023-06-29T08:46:05.073776Z"
    }
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc12b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.074237Z",
     "start_time": "2023-06-29T08:46:05.074232Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(trainer.model)\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "name_model_tflite = 'lavanda.tflite'\n",
    "tflite_model_file = Path(config['MODEL_PATH']).joinpath(name_model_tflite)                          \n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb45330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.074635Z",
     "start_time": "2023-06-29T08:46:05.074630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"bin/lavanda.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db90c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075003Z",
     "start_time": "2023-06-29T08:46:05.074998Z"
    }
   },
   "outputs": [],
   "source": [
    "output_details[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b0717c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# XDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108df2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075422Z",
     "start_time": "2023-06-29T08:46:05.075418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927af9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.075845Z",
     "start_time": "2023-06-29T08:46:05.075840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pixelwise_XDEDLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temp_factor=2.0):\n",
    "        super(pixelwise_XDEDLoss, self).__init__()\n",
    "        self.temp_factor = temp_factor\n",
    "        self.kl_div = tf.keras.losses.KLDivergence(reduction=tf.keras.losses.Reduction.SUM)\n",
    "        self.CLASS_NUM = 1\n",
    "\n",
    "    def xded_loss(self, input, target):\n",
    "        \n",
    "        loss = self.kl_div(tf.nn.softmax(input/self.temp_factor, axis=-1),\n",
    "                           tf.nn.softmax(target/self.temp_factor, axis=-1)) * (self.temp_factor**2)/input.shape[0]\n",
    "        return loss\n",
    "\n",
    "    def call(self, main_out, gts):\n",
    "        # main_out.shape : [batch, 1, 768, 768]\n",
    "        # gts.shape : [batch, 768, 768]\n",
    "\n",
    "        batch_size = main_out.shape[0]\n",
    "        print(batch_size)\n",
    "        flat_gts = tf.reshape(gts,[-1,1]) # [batch*768*768]\n",
    "        flat_out = tf.reshape(main_out,(-1, self.CLASS_NUM))\n",
    "        not_flat_out = not flat_out\n",
    "\n",
    "        flat_targets = tf.reshape(main_out,(-1, self.CLASS_NUM))\n",
    "        # [batch*768*768, 1]\n",
    "\n",
    "        cur_gt_idx = flat_gts == 1 # [False, True, ...]\n",
    "        not_cur_gt_idx = flat_gts == 0 # [True, False, ...]\n",
    "        print(cur_gt_idx.shape)\n",
    "        \n",
    "        x = tf.boolean_mask(flat_out,cur_gt_idx)\n",
    "        not_x = tf.boolean_mask(flat_out,not_cur_gt_idx)\n",
    "        \n",
    "        flat_targets = tf.reduce_mean(x) * tf.cast(cur_gt_idx,tf.float32)\n",
    "        not_flat_targets = tf.reduce_mean(not_x) * tf.cast(not_cur_gt_idx,tf.float32)\n",
    "        print(flat_out.shape, not_flat_out.shape)\n",
    "        print(flat_targets.shape, not_flat_targets.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.xded_loss(flat_out, flat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.076211Z",
     "start_time": "2023-06-29T08:46:05.076206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ys = tf.random.uniform((64,224,224,1))*10\n",
    "y  = tf.cast(tf.random.uniform((64,224,224,1),maxval=2,dtype=tf.int32), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb37f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.076634Z",
     "start_time": "2023-06-29T08:46:05.076630Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(np.min(ys), np.max(ys))\n",
    "print(np.min(y), np.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df79fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.077082Z",
     "start_time": "2023-06-29T08:46:05.077077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(y_pred,y):\n",
    "    l = pixelwise_XDEDLoss()\n",
    "    return l(y_pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da023a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.077473Z",
     "start_time": "2023-06-29T08:46:05.077468Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss(ys,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e633cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.077853Z",
     "start_time": "2023-06-29T08:46:05.077848Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6129f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.078262Z",
     "start_time": "2023-06-29T08:46:05.078257Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class pixelwise_XDEDLoss(torch.nn.Module):\n",
    "    def __init__(self, temp_factor=2.0):\n",
    "        super(pixelwise_XDEDLoss, self).__init__()\n",
    "        self.temp_factor = temp_factor\n",
    "        self.kl_div = torch.nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.CLASS_NUM = 1\n",
    "\n",
    "    def xded_loss(self, input, target):\n",
    "        log_p = torch.log_softmax(input/self.temp_factor, dim=0)\n",
    "        q = torch.softmax(target/self.temp_factor, dim=0)\n",
    "        loss = self.kl_div(log_p, q)*(self.temp_factor**2)/input.size(0)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, main_out, gts):\n",
    "        # main_out.shape : [batch, 19, 768, 768]\n",
    "        # gts.shape : [batch, 768, 768]\n",
    "\n",
    "        batch_size = main_out.shape[0]\n",
    "\n",
    "        flat_gts = gts.reshape(-1) # [batch*768*768]\n",
    "        flat_out = main_out.reshape(-1, self.CLASS_NUM)\n",
    "\n",
    "        flat_targets = main_out.clone().detach().reshape(-1, self.CLASS_NUM)\n",
    "        # [batch*768*768, 19]\n",
    "\n",
    "        flat_gt_set = flat_gts.unique().tolist()\n",
    "        ensemble_dict= {}\n",
    "\n",
    "        for f_gt in flat_gt_set:\n",
    "            if f_gt == 255:\n",
    "                continue\n",
    "            cur_gt_idx = flat_gts == f_gt # [False, True, ...]\n",
    "            flat_targets[cur_gt_idx, :] = flat_out[cur_gt_idx].mean(0).detach()\n",
    "\n",
    "        return self.xded_loss(flat_out, flat_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283a4bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.078658Z",
     "start_time": "2023-06-29T08:46:05.078653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ys = torch.rand((64,1,224,224))\n",
    "y = torch.randint(size=(64,224,224),high=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf021116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.078971Z",
     "start_time": "2023-06-29T08:46:05.078967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = pixelwise_XDEDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e930465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:46:05.079378Z",
     "start_time": "2023-06-29T08:46:05.079373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l(ys,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fc499",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b262a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from utils.instance_norm import _instance_norm_block\n",
    "from utils.tools import read_yaml\n",
    "from utils.data import load_multi_dataset, split_data, random_flip, random_resize_crop, random_jitter, random_grayscale\n",
    "\n",
    "# GPU setup\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", physical_devices)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "devices = []\n",
    "for g in [0]:\n",
    "    tf.config.experimental.set_memory_growth(gpus[g], True)\n",
    "    devices.append(f'GPU:{g}')\n",
    "    \n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "config = read_yaml('utils/config.yaml')\n",
    "config['TARGET'] = 'lettuce'\n",
    "config['NAME'] = 'test'\n",
    "config['ID'] = 0\n",
    "config['STYLE_AUG'] = False\n",
    "config['RND_FLIP'] = 0.0\n",
    "config['RND_CROP'] = 1.0\n",
    "config['RND_GREY'] = 0.0\n",
    "config['RND_JITTER'] = 0.0\n",
    "config['RND_JITTER_RNG'] = 0.0\n",
    "data_dir = Path(config['DATA_PATH'])\n",
    "\n",
    "def get_data(config, data_dir):\n",
    "\n",
    "    target_dataset = data_dir.joinpath(config['TARGET'])\n",
    "    source_dataset = sorted([data_dir.joinpath(d) for d in config['SOURCE'] if d != config['TARGET']])\n",
    "    \n",
    "    ds_source, ds_target = load_multi_dataset(source_dataset, target_dataset, config)\n",
    "    ds_train, ds_val, ds_test = split_data(ds_source, ds_target, config)\n",
    "    \n",
    "    train_len = len(ds_train)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(train_len)\n",
    "    ds_train = ds_train.map(lambda x, y: random_flip(x, y, p=config['RND_FLIP']), tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.map(lambda x, y: random_resize_crop(x, y, min_p=config['RND_CROP']), tf.data.experimental.AUTOTUNE)\n",
    "    if config['STYLE_AUG']:\n",
    "        ds_train = ds_train.map(lambda x, y: random_jitter(x, y, p=config['RND_JITTER'], r=config['RND_JITTER_RNG']), tf.data.experimental.AUTOTUNE)\n",
    "        ds_train = ds_train.map(lambda x, y: random_grayscale(x, y, p=config['RND_GREY']), tf.data.experimental.AUTOTUNE)\n",
    "    ds_train = ds_train.batch(8, drop_remainder=True)\n",
    "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_len = 0\n",
    "\n",
    "    if ds_test is not None:\n",
    "        test_len = len(ds_test)\n",
    "        # ds_test = ds_test.cache()\n",
    "        ds_train = ds_train.shuffle(test_len)\n",
    "        ds_test = ds_test.batch(8, drop_remainder=False)\n",
    "        ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    else: \n",
    "        test_len = 0\n",
    "        \n",
    "    print(f'Loaded data: Train {train_len}, Val {val_len}, Test {test_len}')\n",
    "    return ds_train, ds_val, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643211c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = get_data(config, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e962792",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (x, y) in enumerate(ds_test, 1):\n",
    "    # aug_x = _instance_norm_block(x, mode='KD_WCTA', training=True)\n",
    "    for i in range(x.shape[0]):\n",
    "        print(tf.reduce_min(x[i]), tf.reduce_max(x[i]), tf.reduce_mean(x[i]))\n",
    "        plt.imshow(x[i]*std+mean)\n",
    "        print(tf.reduce_min(x[i]*std+mean), tf.reduce_max(x[i]*std+mean), tf.reduce_mean(x[i]*std+mean))\n",
    "        plt.show()\n",
    "        # plt.imshow(aug_x[i]*std+mean)\n",
    "        # plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open('../AgriSeg_Dataset/lettuce/lettuce_1/images/Image10/Image0001.png'))[:,:,:3]\n",
    "img = img/255.0\n",
    "img -= [0.485, 0.456, 0.406]\n",
    "img /= [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min(), img.max(), img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mobilenet_v3_2 import MobileNetV3Large\n",
    "\n",
    "model = MobileNetV3Large(\n",
    "    input_shape=(224,224,3),\n",
    "    alpha=1.0,\n",
    "    minimalistic=False,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    classes=1,\n",
    "    pooling='avg',\n",
    "    dropout_rate=False,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d02216",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4de925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
